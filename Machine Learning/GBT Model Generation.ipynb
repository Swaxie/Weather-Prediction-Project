{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bb68209-2055-4082-949d-07f78179d4a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, floor, when, concat_ws, to_timestamp, lpad, lag, lead, avg, hour, dayofyear\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import Row\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b74c4c59-e517-4671-af88-efa969d88949",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "# Loading in data for cities that need GBT model\n",
    "cities_list = ['Amsterdam', 'Copenhagen', 'Dublin', 'Antwerp']\n",
    "api_forecasts_df = spark.read.parquet('/mnt/de-upskilling-weather/Gold/7day_hourly_forecast.parquet/').where(col('city').isin(cities_list)).select('date', 'city', 'temperature_2m', 'dew_point_2m', 'shortwave_radiation', 'surface_pressure', 'pressure_msl', 'cloud_cover', 'relative_humidity_2m').orderBy('city','date')\n",
    "hourly_historical = spark.read.parquet('/mnt/de-upskilling-weather/Gold/hourly_historical.parquet/').where(col('city').isin(cities_list))\n",
    "\n",
    "# Model generation preparation\n",
    "feature_columns = ['temp_lag_1hr', 'rolling_temp_avg3hr', 'temp_lag_3hr', 'rolling_temp_avg6hr', 'dew_point_2m', 'season', 'shortwave_radiation', 'month', 'day_of_year', 'pressure_msl', 'surface_pressure', 'hour', 'cloud_cover', 'temp_lag_1day', 'rolling_temp_avg1day']\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n",
    "gbt = GBTRegressor(labelCol=\"temperature_2m\", featuresCol=\"features\", maxIter=150, maxDepth=7, stepSize=0.05)\n",
    "\n",
    "# lag and rolling windows\n",
    "lag_window = Window.orderBy('datetime')\n",
    "rolling_window_3hr = Window.orderBy('datetime').rowsBetween(-3, -1)\n",
    "rolling_window_6hr = Window.orderBy('datetime').rowsBetween(-6, -1)\n",
    "rolling_window_12hr = Window.orderBy('datetime').rowsBetween(-12, -1)\n",
    "rolling_window_24hr = Window.orderBy('datetime').rowsBetween(-24, -1) \n",
    "\n",
    "# season feature dictionary\n",
    "month_to_season = {\n",
    "    12: 0, 1: 0, 2: 0,  # Winter\n",
    "    3: 1, 4: 1, 5: 1,  # Spring\n",
    "    6: 2, 7: 2, 8: 2,  # Summer\n",
    "    9: 3, 10: 3, 11: 3  # Fall\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17e8ba82-8bd2-4a56-a175-eca41cbe4b7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model Generation\n",
    "for city in cities_list:\n",
    "\n",
    "    city_no_ws = re.sub(r'\\W+', '', city)\n",
    "    model_path = f'/mnt/de-upskilling-weather/MachineLearning/{city_no_ws}_forecast_model'\n",
    "    # getting dataset for specific city\n",
    "    df = hourly_historical.where(col('city') == city)\n",
    "    df = df.drop('city').orderBy('datetime')\n",
    "\n",
    "    # temperature lags\n",
    "    df = df.withColumn('temp_lag_1hr', lag('temperature_2m', 1).over(lag_window))\n",
    "    df = df.withColumn('temp_lag_3hr', lag('temperature_2m', 3).over(lag_window))\n",
    "    df = df.withColumn('temp_lag_1day', lag('temperature_2m', 24).over(lag_window))\n",
    "\n",
    "    # temperature rolling averages\n",
    "    df = df.withColumn('rolling_temp_avg3hr', avg('temperature_2m').over(rolling_window_3hr))\n",
    "    df = df.withColumn('rolling_temp_avg6hr', avg('temperature_2m').over(rolling_window_6hr))\n",
    "    df = df.withColumn('rolling_temp_avg1day', avg('temperature_2m').over(rolling_window_24hr))\n",
    "\n",
    "\n",
    "    # dropping all nulls created from lags\n",
    "    df = df.dropna()\n",
    "\n",
    "    # vectorizing features, generating model, and saving model\n",
    "    train_data = assembler.transform(df).select('features', 'temperature_2m')\n",
    "    forecast_model = gbt.fit(train_data)\n",
    "\n",
    "    forecast_model.write().overwrite().save(model_path)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "GBT Model Generation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}