{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1a4a18f-c6f4-4e6c-9d32-37406eabb32f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openmeteo-requests\n  Obtaining dependency information for openmeteo-requests from https://files.pythonhosted.org/packages/13/31/96209383687cf35055eb628e3a9207a07ac2d5faf6e70076f459435a989e/openmeteo_requests-1.3.0-py3-none-any.whl.metadata\n  Downloading openmeteo_requests-1.3.0-py3-none-any.whl.metadata (9.7 kB)\nCollecting openmeteo-sdk>=1.4.0 (from openmeteo-requests)\n  Obtaining dependency information for openmeteo-sdk>=1.4.0 from https://files.pythonhosted.org/packages/18/9a/f33c4eb783d505d0099c039bbac30da09266027d9e3e0b5de76ef796749d/openmeteo_sdk-1.18.0-py3-none-any.whl.metadata\n  Downloading openmeteo_sdk-1.18.0-py3-none-any.whl.metadata (934 bytes)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.11/site-packages (from openmeteo-requests) (2.31.0)\nCollecting flatbuffers>=24.0.0 (from openmeteo-sdk>=1.4.0->openmeteo-requests)\n  Obtaining dependency information for flatbuffers>=24.0.0 from https://files.pythonhosted.org/packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl.metadata\n  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests->openmeteo-requests) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests->openmeteo-requests) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests->openmeteo-requests) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests->openmeteo-requests) (2023.7.22)\nDownloading openmeteo_requests-1.3.0-py3-none-any.whl (6.0 kB)\nDownloading openmeteo_sdk-1.18.0-py3-none-any.whl (7.6 kB)\nDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\nInstalling collected packages: flatbuffers, openmeteo-sdk, openmeteo-requests\nSuccessfully installed flatbuffers-24.3.25 openmeteo-requests-1.3.0 openmeteo-sdk-1.18.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting requests-cache\n  Obtaining dependency information for requests-cache from https://files.pythonhosted.org/packages/4e/2e/8f4051119f460cfc786aa91f212165bb6e643283b533db572d7b33952bd2/requests_cache-1.2.1-py3-none-any.whl.metadata\n  Downloading requests_cache-1.2.1-py3-none-any.whl.metadata (9.9 kB)\nCollecting retry-requests\n  Obtaining dependency information for retry-requests from https://files.pythonhosted.org/packages/b1/f3/8ce908497bebbc2790ef06240a2c0fb28c096abb59062d88f85090464a5f/retry_requests-2.0.0-py3-none-any.whl.metadata\n  Downloading retry_requests-2.0.0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.11/site-packages (1.23.5)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.11/site-packages (1.5.3)\nCollecting attrs>=21.2 (from requests-cache)\n  Obtaining dependency information for attrs>=21.2 from https://files.pythonhosted.org/packages/6a/21/5b6702a7f963e95456c0de2d495f67bf5fd62840ac655dc451586d23d39a/attrs-24.2.0-py3-none-any.whl.metadata\n  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\nCollecting cattrs>=22.2 (from requests-cache)\n  Obtaining dependency information for cattrs>=22.2 from https://files.pythonhosted.org/packages/c8/d5/867e75361fc45f6de75fe277dd085627a9db5ebb511a87f27dc1396b5351/cattrs-24.1.2-py3-none-any.whl.metadata\n  Downloading cattrs-24.1.2-py3-none-any.whl.metadata (8.4 kB)\nRequirement already satisfied: platformdirs>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests-cache) (3.10.0)\nRequirement already satisfied: requests>=2.22 in /databricks/python3/lib/python3.11/site-packages (from requests-cache) (2.31.0)\nCollecting url-normalize>=1.4 (from requests-cache)\n  Obtaining dependency information for url-normalize>=1.4 from https://files.pythonhosted.org/packages/65/1c/6c6f408be78692fc850006a2b6dea37c2b8592892534e09996e401efc74b/url_normalize-1.4.3-py2.py3-none-any.whl.metadata\n  Downloading url_normalize-1.4.3-py2.py3-none-any.whl.metadata (3.1 kB)\nRequirement already satisfied: urllib3>=1.25.5 in /databricks/python3/lib/python3.11/site-packages (from requests-cache) (1.26.16)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.11/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas) (2022.7)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.22->requests-cache) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.22->requests-cache) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.22->requests-cache) (2023.7.22)\nDownloading requests_cache-1.2.1-py3-none-any.whl (61 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/61.4 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.4/61.4 kB\u001B[0m \u001B[31m4.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading retry_requests-2.0.0-py3-none-any.whl (15 kB)\nDownloading attrs-24.2.0-py3-none-any.whl (63 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/63.0 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m63.0/63.0 kB\u001B[0m \u001B[31m7.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading cattrs-24.1.2-py3-none-any.whl (66 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/66.4 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m66.4/66.4 kB\u001B[0m \u001B[31m8.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\nInstalling collected packages: url-normalize, attrs, retry-requests, cattrs, requests-cache\nSuccessfully installed attrs-24.2.0 cattrs-24.1.2 requests-cache-1.2.1 retry-requests-2.0.0 url-normalize-1.4.3\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install openmeteo-requests\n",
    "%pip install requests-cache retry-requests numpy pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9011b901-c770-4865-aa43-58cc76bbf95d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import openmeteo_requests\n",
    "from datetime import datetime, timedelta\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "from retry_requests import retry\n",
    "from pyspark.sql.functions import col, max as spark_max\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91a42d3e-4872-4cce-9fe6-6e066bc0516e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion will start from: 2022-01-01\nEnd date is set to: 2024-09-01\n"
     ]
    }
   ],
   "source": [
    "# Define S3 bucket details and file path\n",
    "bucket_name = \"de-upskilling-weather\"\n",
    "folder = \"LandingZone\"\n",
    "file_name = \"hourly_historical_forecast.parquet\"\n",
    "s3_path = f\"/mnt/{bucket_name}/{folder}/{file_name}\"\n",
    "\n",
    "# Default start date\n",
    "start_date = \"2022-01-01\"\n",
    "\n",
    "end_date = \"2024-09-01\"#(datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "print(\"Ingestion will start from:\", start_date)\n",
    "\n",
    "print(\"End date is set to:\", end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "516455cd-8f62-4be0-a8bd-1307ea8efee3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeError: strptime() argument 1 must be str, not datetime.datetime\n"
     ]
    }
   ],
   "source": [
    "# Initialize cache and retry session\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after=3600)\n",
    "retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "# Define the date ranges\n",
    "start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "end_date_ = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "# Make sure all required weather variables are listed here\n",
    "# The order of variables in hourly or daily is important to assign them correctly below\n",
    "url = \"https://historical-forecast-api.open-meteo.com/v1/forecast\"\n",
    "\n",
    "# Define location and timezone data\n",
    "latitudes = [38.855584, 40.724039, 25.695215, 34.005712, 32.724548, 47.594472, 39.676938, 39.952583, 39.791, 35.481918, 36.174465, 41.881832, 51.509865, 52.520008, 48.137154, 48.864716, 47.373878, 51.260197, 52.377956, 53.35014, 40.416775, 48.210033, 46.056946, 50.073658, 55.676098]\n",
    "longitudes = [-77.036975, -73.994982, -80.168933, -118.175596, -96.76923, -122.348286, -104.977053, -75.165222, -86.148003, -97.508469, -86.76796, -87.623177, -0.118092, 13.404954, 11.576124, 2.349014, 8.545094, 4.402771, 4.89707, -6.266155, -3.70379, 16.363449, 14.505751, 14.41854, 12.568337]\n",
    "timezones = [\"America/New_York\", \"America/New_York\", \"America/New_York\", \"America/Los_Angeles\", \"America/Chicago\", \"America/Los_Angeles\", \"America/Denver\", \"America/New_York\", \"America/Indiana/Indianapolis\", \"America/Chicago\", \"America/Chicago\", \"America/Chicago\", \"Europe/London\", \"Europe/Berlin\", \"Europe/Berlin\", \"Europe/Paris\", \"Europe/Zurich\", \"Europe/Brussels\", \"Europe/Amsterdam\", \"Europe/Dublin\", \"Europe/Madrid\", \"Europe/Vienna\", \"Europe/Ljubljana\", \"Europe/Prague\", \"Europe/Copenhagen\"]\n",
    "\n",
    "# Parameters for the API\n",
    "params_template = {\n",
    "    \"latitude\": latitudes,\n",
    "    \"longitude\": longitudes,\n",
    "    \"hourly\": [\"temperature_2m\", \"relative_humidity_2m\", \"precipitation\", \"rain\", \"showers\", \"snowfall\", \"snow_depth\", \"weather_code\", \"wind_speed_10m\", \"wind_speed_80m\", \"wind_speed_120m\", \"wind_speed_180m\", \"wind_direction_10m\", \"wind_direction_80m\", \"wind_direction_120m\", \"wind_direction_180m\", \"wind_gusts_10m\"],\n",
    "    \"timezone\": \"GMT\" #timezones\n",
    "}\n",
    "\n",
    "# Initialize responses list\n",
    "responses = []\n",
    "\n",
    "# Iterate over year-long periods\n",
    "current_start_date = start_date\n",
    "while current_start_date < end_date_:\n",
    "    # Set the end date for the current year period or cap it at the final end date\n",
    "    current_end_date = min(current_start_date.replace(year=current_start_date.year + 1) - timedelta(days=1), end_date_)\n",
    "    \n",
    "    # Update parameters with the current date range\n",
    "    params = params_template.copy()\n",
    "    params[\"start_date\"] = current_start_date.strftime(\"%Y-%m-%d\")\n",
    "    params[\"end_date\"] = current_end_date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Make the API call and add the response to the list\n",
    "    response = openmeteo.weather_api(url, params=params)\n",
    "    responses.extend(response)\n",
    "    \n",
    "    # Move to the next period (start date of next year)\n",
    "    current_start_date = current_end_date + timedelta(days=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a44b825-850b-48dc-8c1d-8fb530f0a553",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91bd4584-8d14-470e-8152-4bc9af511b3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n"
     ]
    }
   ],
   "source": [
    "for i, response in enumerate(responses):\n",
    "    # Process first location. Add a for-loop for multiple locations or weather models\n",
    "    #response = responses[0]\n",
    "    #print(f\"Coordinates {response.Latitude()}°N {response.Longitude()}°E\")\n",
    "    #print(f\"Elevation {response.Elevation()} m asl\")\n",
    "    #print(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\n",
    "    #print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n",
    "\n",
    "    # Process hourly data. The order of variables needs to be the same as requested.\n",
    "    hourly = response.Hourly()\n",
    "    hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "    hourly_relative_humidity_2m = hourly.Variables(1).ValuesAsNumpy()\n",
    "    hourly_precipitation = hourly.Variables(2).ValuesAsNumpy()\n",
    "    hourly_rain = hourly.Variables(3).ValuesAsNumpy()\n",
    "    hourly_showers = hourly.Variables(4).ValuesAsNumpy()\n",
    "    hourly_snowfall = hourly.Variables(5).ValuesAsNumpy()\n",
    "    hourly_snow_depth = hourly.Variables(6).ValuesAsNumpy()\n",
    "    hourly_weather_code = hourly.Variables(7).ValuesAsNumpy()\n",
    "    hourly_wind_speed_10m = hourly.Variables(8).ValuesAsNumpy()\n",
    "    hourly_wind_speed_80m = hourly.Variables(9).ValuesAsNumpy()\n",
    "    hourly_wind_speed_120m = hourly.Variables(10).ValuesAsNumpy()\n",
    "    hourly_wind_speed_180m = hourly.Variables(11).ValuesAsNumpy()\n",
    "    hourly_wind_direction_10m = hourly.Variables(12).ValuesAsNumpy()\n",
    "    hourly_wind_direction_80m = hourly.Variables(13).ValuesAsNumpy()\n",
    "    hourly_wind_direction_120m = hourly.Variables(14).ValuesAsNumpy()\n",
    "    hourly_wind_direction_180m = hourly.Variables(15).ValuesAsNumpy()\n",
    "    hourly_wind_gusts_10m = hourly.Variables(16).ValuesAsNumpy()\n",
    "\n",
    "    hourly_data = {\"date\": pd.date_range(\n",
    "        start = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
    "        end = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
    "        freq = pd.Timedelta(seconds = hourly.Interval()),\n",
    "        inclusive = \"left\"\n",
    "    )}\n",
    "    \n",
    "    hourly_data[\"latitude\"] = latitudes[i%len(latitudes)]\n",
    "    hourly_data[\"longitude\"] = longitudes[i%len(latitudes)]\n",
    "    hourly_data[\"timezone\"] = timezones[i%len(latitudes)]\n",
    "    \n",
    "    hourly_data[\"temperature_2m\"] = hourly_temperature_2m\n",
    "    hourly_data[\"relative_humidity_2m\"] = hourly_relative_humidity_2m\n",
    "    hourly_data[\"precipitation\"] = hourly_precipitation\n",
    "    hourly_data[\"rain\"] = hourly_rain\n",
    "    hourly_data[\"showers\"] = hourly_showers\n",
    "    hourly_data[\"snowfall\"] = hourly_snowfall\n",
    "    hourly_data[\"snow_depth\"] = hourly_snow_depth\n",
    "    hourly_data[\"weather_code\"] = hourly_weather_code\n",
    "    hourly_data[\"wind_speed_10m\"] = hourly_wind_speed_10m\n",
    "    hourly_data[\"wind_speed_80m\"] = hourly_wind_speed_80m\n",
    "    hourly_data[\"wind_speed_120m\"] = hourly_wind_speed_120m\n",
    "    hourly_data[\"wind_speed_180m\"] = hourly_wind_speed_180m\n",
    "    hourly_data[\"wind_direction_10m\"] = hourly_wind_direction_10m\n",
    "    hourly_data[\"wind_direction_80m\"] = hourly_wind_direction_80m\n",
    "    hourly_data[\"wind_direction_120m\"] = hourly_wind_direction_120m\n",
    "    hourly_data[\"wind_direction_180m\"] = hourly_wind_direction_180m\n",
    "    hourly_data[\"wind_gusts_10m\"] = hourly_wind_gusts_10m\n",
    "\n",
    "    hourly_dataframe = pd.DataFrame(data = hourly_data)\n",
    "    \n",
    "    if i == 0:\n",
    "        # Convert `daily_dataframe` to a Spark DataFrame\n",
    "        spark_df = spark.createDataFrame(hourly_dataframe)\n",
    "    else:\n",
    "        # Convert `daily_dataframe` to a Spark DataFrame\n",
    "        hourly_spark_df = spark.createDataFrame(hourly_dataframe)\n",
    "\n",
    "        # Concatenate the two Spark DataFrames\n",
    "        spark_df = spark_df.unionByName(hourly_spark_df)\n",
    "    \n",
    "    #print(hourly_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acf51e7f-9a74-432a-b91b-077deb4c2ad4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+----------+----------------+------------------+--------------------+-----------------+-----------------+-------+--------+----------+------------+------------------+------------------+------------------+---------------+------------------+------------------+-------------------+-------------------+------------------+\n|               date| latitude| longitude|        timezone|    temperature_2m|relative_humidity_2m|    precipitation|             rain|showers|snowfall|snow_depth|weather_code|    wind_speed_10m|    wind_speed_80m|   wind_speed_120m|wind_speed_180m|wind_direction_10m|wind_direction_80m|wind_direction_120m|wind_direction_180m|    wind_gusts_10m|\n+-------------------+---------+----------+----------------+------------------+--------------------+-----------------+-----------------+-------+--------+----------+------------+------------------+------------------+------------------+---------------+------------------+------------------+-------------------+-------------------+------------------+\n|2022-01-01 05:00:00|38.855584|-77.036975|America/New_York|12.187000274658203|                94.0|              0.0|              0.0|    0.0|     0.0|       0.0|         3.0| 4.452953815460205|15.946009635925293| 20.74689483642578|            NaN| 75.96372985839844| 151.6993408203125|    157.06787109375|                NaN| 8.640000343322754|\n|2022-01-01 06:00:00|38.855584|-77.036975|America/New_York| 12.53700065612793|                93.0|              0.0|              0.0|    0.0|     0.0|       0.0|         3.0|1.0182337760925293|13.627795219421387|22.926414489746094|            NaN| 315.0000915527344|167.79954528808594| 173.55850219726562|                NaN|14.039999961853027|\n|2022-01-01 07:00:00|38.855584|-77.036975|America/New_York|12.487000465393066|                94.0|              0.0|              0.0|    0.0|     0.0|       0.0|         3.0|2.9686360359191895|17.935081481933594| 23.26837921142578|            NaN| 75.96372985839844|169.59234619140625| 195.57260131835938|                NaN|              18.0|\n|2022-01-01 08:00:00|38.855584|-77.036975|America/New_York|12.837000846862793|                94.0|              0.0|              0.0|    0.0|     0.0|       0.0|         3.0| 2.545584201812744| 17.10662841796875| 23.56818199157715|            NaN|135.00010681152344|188.47105407714844| 210.96368408203125|                NaN|12.239999771118164|\n|2022-01-01 09:00:00|38.855584|-77.036975|America/New_York|13.687000274658203|                94.0|              0.0|              0.0|    0.0|     0.0|       0.0|         3.0| 6.287129878997803|21.611997604370117| 20.94766616821289|            NaN| 166.7594757080078| 181.9091033935547|  217.8750457763672|                NaN|17.639999389648438|\n|2022-01-01 10:00:00|38.855584|-77.036975|America/New_York|13.937000274658203|                98.0|              0.0|              0.0|    0.0|     0.0|       0.0|         3.0| 5.154415607452393| 16.56391143798828|20.048568725585938|            NaN|167.90525817871094|181.24533081054688| 221.28460693359375|                NaN|16.559999465942383|\n|2022-01-01 11:00:00|38.855584|-77.036975|America/New_York|13.837000846862793|                97.0|              0.0|              0.0|    0.0|     0.0|       0.0|         3.0| 7.199999809265137|15.844090461730957|       12.43359375|            NaN|             180.0| 181.3019256591797|  235.8402557373047|                NaN| 23.03999900817871|\n|2022-01-01 12:00:00|38.855584|-77.036975|America/New_York| 13.88700008392334|                95.0|              0.0|              0.0|    0.0|     0.0|       0.0|         3.0| 5.039999961853027|15.629972457885742|13.510838508605957|            NaN|             180.0|172.05662536621094|  202.3801727294922|                NaN|21.959999084472656|\n|2022-01-01 13:00:00|38.855584|-77.036975|America/New_York|13.837000846862793|                96.0|              0.0|              0.0|    0.0|     0.0|       0.0|         3.0| 4.320000171661377|16.595178604125977|13.233170509338379|            NaN|             180.0| 176.2686767578125|  178.4088897705078|                NaN|17.280000686645508|\n|2022-01-01 14:00:00|38.855584|-77.036975|America/New_York|14.087000846862793|                97.0|1.100000023841858|1.100000023841858|    0.0|     0.0|       0.0|        55.0|1.0800000429153442|  7.56856632232666|18.375993728637695|            NaN|             180.0|177.27374267578125| 178.85426330566406|                NaN| 7.920000076293945|\n|2022-01-01 15:00:00|38.855584|-77.036975|America/New_York| 14.28700065612793|                98.0|2.200000047683716|2.200000047683716|    0.0|     0.0|       0.0|        61.0| 3.239999771118164|  5.86037540435791|24.793781280517578|            NaN|              90.0|137.48959350585938|  186.8089599609375|                NaN| 12.59999942779541|\n|2022-01-01 16:00:00|38.855584|-77.036975|America/New_York| 14.53700065612793|                96.0|0.699999988079071|0.699999988079071|    0.0|     0.0|       0.0|        53.0|1.1384198665618896| 5.241678714752197| 32.58692169189453|            NaN|  71.5649642944336|164.05453491210938|  172.8750762939453|                NaN|13.319999694824219|\n|2022-01-01 17:00:00|38.855584|-77.036975|America/New_York|14.987000465393066|                97.0|0.699999988079071|0.699999988079071|    0.0|     0.0|       0.0|        53.0|2.9024126529693604| 2.741678237915039| 23.69957733154297|            NaN|352.87506103515625|156.80137634277344|  172.8750762939453|                NaN|               9.0|\n|2022-01-01 18:00:00|38.855584|-77.036975|America/New_York|15.187000274658203|                94.0|              0.0|              0.0|    0.0|     0.0|       0.0|         3.0|3.3190360069274902| 9.422101020812988|19.530040740966797|            NaN|130.60121154785156|133.45188903808594| 191.94415283203125|                NaN|13.319999694824219|\n|2022-01-01 19:00:00|38.855584|-77.036975|America/New_York| 15.38700008392334|                94.0|              0.0|              0.0|    0.0|     0.0|       0.0|         3.0|2.6208393573760986| 7.862518310546875| 16.31726837158203|            NaN|195.94546508789062|164.05453491210938| 172.23492431640625|                NaN|21.239999771118164|\n|2022-01-01 20:00:00|38.855584|-77.036975|America/New_York|15.687000274658203|                96.0|              0.0|              0.0|    0.0|     0.0|       0.0|         3.0| 2.811689853668213| 8.654986381530762|13.319613456726074|            NaN|140.19447326660156|163.07240295410156| 204.44393920898438|                NaN|19.799999237060547|\n|2022-01-01 21:00:00|38.855584|-77.036975|America/New_York| 15.88700008392334|                94.0|              0.0|              0.0|    0.0|     0.0|       0.0|         3.0|1.4843180179595947| 8.759178161621094| 9.037985801696777|            NaN|255.96372985839844|189.46224975585938|  206.5649871826172|                NaN| 12.59999942779541|\n|2022-01-01 22:00:00|38.855584|-77.036975|America/New_York| 15.63700008392334|                94.0|              0.0|              0.0|    0.0|     0.0|       0.0|         3.0|2.1897945404052734| 11.65977668762207|1.8372317552566528|            NaN|189.46224975585938|171.11941528320312|              180.0|                NaN|16.559999465942383|\n|2022-01-01 23:00:00|38.855584|-77.036975|America/New_York|16.086999893188477|                94.0|              0.0|              0.0|    0.0|     0.0|       0.0|         3.0|1.2979984283447266|12.768586158752441| 9.995620727539062|            NaN|123.69009399414062|158.49850463867188| 162.89718627929688|                NaN|13.319999694824219|\n|2022-01-02 00:00:00|38.855584|-77.036975|America/New_York|16.286998748779297|                95.0|              0.0|              0.0|    0.0|     0.0|       0.0|         3.0| 2.811689853668213| 5.815978050231934|19.181262969970703|            NaN| 39.80552673339844|111.80147552490234|  159.8292694091797|                NaN| 6.479999542236328|\n+-------------------+---------+----------+----------------+------------------+--------------------+-----------------+-----------------+-------+--------+----------+------------+------------------+------------------+------------------+---------------+------------------+------------------+-------------------+-------------------+------------------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "#spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f71d7750-3d05-4a2a-af98-28dc9128c6db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- date: timestamp (nullable = true)\n |-- latitude: double (nullable = true)\n |-- longitude: double (nullable = true)\n |-- timezone: string (nullable = true)\n |-- temperature_2m: double (nullable = true)\n |-- relative_humidity_2m: double (nullable = true)\n |-- precipitation: double (nullable = true)\n |-- rain: double (nullable = true)\n |-- showers: double (nullable = true)\n |-- snowfall: double (nullable = true)\n |-- snow_depth: double (nullable = true)\n |-- weather_code: double (nullable = true)\n |-- wind_speed_10m: double (nullable = true)\n |-- wind_speed_80m: double (nullable = true)\n |-- wind_speed_120m: double (nullable = true)\n |-- wind_speed_180m: double (nullable = true)\n |-- wind_direction_10m: double (nullable = true)\n |-- wind_direction_80m: double (nullable = true)\n |-- wind_direction_120m: double (nullable = true)\n |-- wind_direction_180m: double (nullable = true)\n |-- wind_gusts_10m: double (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e079175b-b64b-4173-8244-495c7f08575a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585000\n"
     ]
    }
   ],
   "source": [
    "spark_df.count() #615600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a002385a-4f3a-4cbb-b7fa-4ccee93a9c2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.write.mode(\"overwrite\").parquet(s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d64f0b0e-ef07-4c41-9289-af3d2f513261",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------------------+\n|           file_name|latest_data|       date_updated|\n+--------------------+-----------+-------------------+\n|hourly_historical...| 2024-09-01|2024-12-10 16:09:03|\n+--------------------+-----------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from datetime import datetime\n",
    "\n",
    "# Get current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "# Format date and time as a string\n",
    "formatted_date_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    (file_name, end_date, formatted_date_time)\n",
    "]\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"file_name\", StringType(), True),\n",
    "    StructField(\"latest_data\", StringType(), True),\n",
    "    StructField(\"date_updated\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create DataFrame\n",
    "df_log = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Show DataFrame\n",
    "df_log.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daa87fd9-ff80-493b-bfd9-86097c462d9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#615600\n",
    "df_log.write.mode(\"append\").parquet(f\"/mnt/{bucket_name}/Gold/log.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d12a8af-e61b-401c-a76a-75308fe344ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "hourly_historical_forecast.ipynb",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Glue PySpark",
   "language": "python",
   "name": "glue_pyspark"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}